{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM7DdmYVDDJzAx3zo4Xu7V9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RaviKcse08/datascience_projs/blob/main/FeedForwardNeuralNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialization: Load shared functions and simulated data \n",
        "\n",
        "# Load shared functions\n",
        "!curl -O https://raw.githubusercontent.com/Fraud-Detection-Handbook/fraud-detection-handbook/main/Chapter_References/shared_functions.py\n",
        "%run shared_functions.py\n",
        "import os\n",
        "# Get simulated data from Github repository\n",
        "if not os.path.exists(\"simulated-data-transformed\"):\n",
        "    !git clone https://github.com/Fraud-Detection-Handbook/simulated-data-transformed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNBBURM_ykSe",
        "outputId": "ccd5acb1-4d72-43a5-c5a0-fca0d6673d7a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 63257  100 63257    0     0   272k      0 --:--:-- --:--:-- --:--:--  272k\n",
            "Cloning into 'simulated-data-transformed'...\n",
            "remote: Enumerating objects: 189, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 189 (delta 0), reused 3 (delta 0), pack-reused 186\u001b[K\n",
            "Receiving objects: 100% (189/189), 70.08 MiB | 18.54 MiB/s, done.\n",
            "Resolving deltas: 100% (3/3), done.\n",
            "Updating files: 100% (184/184), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data loading\n",
        "#import pandas as pd\n",
        "#transactions_df = pd.read_csv('final_dataset_fd.csv') \n",
        "#transactions_df.tail()"
      ],
      "metadata": {
        "id": "bzletZcevplT"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgiSIa5CvCMS",
        "outputId": "27f7e750-aaa4-4c48-bda1-087557f4862f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load  files\n",
            "CPU times: user 392 ms, sys: 212 ms, total: 604 ms\n",
            "Wall time: 619 ms\n",
            "919767 transactions loaded, containing 8195 fraudulent transactions\n"
          ]
        }
      ],
      "source": [
        "DIR_INPUT='simulated-data-transformed/data/' \n",
        "\n",
        "BEGIN_DATE = \"2018-06-11\"\n",
        "END_DATE = \"2018-09-14\"\n",
        "\n",
        "print(\"Load  files\")\n",
        "%time transactions_df=read_from_files(DIR_INPUT, BEGIN_DATE, END_DATE)\n",
        "print(\"{0} transactions loaded, containing {1} fraudulent transactions\".format(len(transactions_df),transactions_df.TX_FRAUD.sum()))\n",
        "\n",
        "output_feature=\"TX_FRAUD\"\n",
        "\n",
        "input_features=['TX_AMOUNT','TX_DURING_WEEKEND', 'TX_DURING_NIGHT', 'CUSTOMER_ID_NB_TX_1DAY_WINDOW',\n",
        "       'CUSTOMER_ID_AVG_AMOUNT_1DAY_WINDOW', 'CUSTOMER_ID_NB_TX_7DAY_WINDOW',\n",
        "       'CUSTOMER_ID_AVG_AMOUNT_7DAY_WINDOW', 'CUSTOMER_ID_NB_TX_30DAY_WINDOW',\n",
        "       'CUSTOMER_ID_AVG_AMOUNT_30DAY_WINDOW', 'TERMINAL_ID_NB_TX_1DAY_WINDOW',\n",
        "       'TERMINAL_ID_RISK_1DAY_WINDOW', 'TERMINAL_ID_NB_TX_7DAY_WINDOW',\n",
        "       'TERMINAL_ID_RISK_7DAY_WINDOW', 'TERMINAL_ID_NB_TX_30DAY_WINDOW',\n",
        "       'TERMINAL_ID_RISK_30DAY_WINDOW']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transactions_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "LujwGED253an",
        "outputId": "333de839-8904-4c02-d6f6-f68303b66cf5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   TRANSACTION_ID         TX_DATETIME  CUSTOMER_ID  TERMINAL_ID  TX_AMOUNT  \\\n",
              "0          680886 2018-06-11 00:00:24         3711         8121      75.81   \n",
              "1          680887 2018-06-11 00:00:25         1320          867     101.89   \n",
              "2          680888 2018-06-11 00:01:46          824         7954      44.72   \n",
              "3          680889 2018-06-11 00:02:40         1085         8595      23.08   \n",
              "4          680890 2018-06-11 00:02:55          346         4909      98.13   \n",
              "\n",
              "   TX_TIME_SECONDS  TX_TIME_DAYS  TX_FRAUD  TX_FRAUD_SCENARIO  \\\n",
              "0          6134424            71         0                  0   \n",
              "1          6134425            71         0                  0   \n",
              "2          6134506            71         0                  0   \n",
              "3          6134560            71         0                  0   \n",
              "4          6134575            71         0                  0   \n",
              "\n",
              "   TX_DURING_WEEKEND  ...  CUSTOMER_ID_NB_TX_7DAY_WINDOW  \\\n",
              "0                  0  ...                           34.0   \n",
              "1                  0  ...                           27.0   \n",
              "2                  0  ...                           23.0   \n",
              "3                  0  ...                           24.0   \n",
              "4                  0  ...                            7.0   \n",
              "\n",
              "   CUSTOMER_ID_AVG_AMOUNT_7DAY_WINDOW  CUSTOMER_ID_NB_TX_30DAY_WINDOW  \\\n",
              "0                           69.421471                           124.0   \n",
              "1                           92.666667                           117.0   \n",
              "2                           37.035217                            80.0   \n",
              "3                           55.140833                           101.0   \n",
              "4                           57.628571                            38.0   \n",
              "\n",
              "   CUSTOMER_ID_AVG_AMOUNT_30DAY_WINDOW  TERMINAL_ID_NB_TX_1DAY_WINDOW  \\\n",
              "0                            70.598710                            2.0   \n",
              "1                            83.699402                            1.0   \n",
              "2                            40.290125                            2.0   \n",
              "3                            54.151386                            1.0   \n",
              "4                            63.603158                            4.0   \n",
              "\n",
              "   TERMINAL_ID_RISK_1DAY_WINDOW  TERMINAL_ID_NB_TX_7DAY_WINDOW  \\\n",
              "0                           0.0                           10.0   \n",
              "1                           0.0                           10.0   \n",
              "2                           0.0                           14.0   \n",
              "3                           0.0                            8.0   \n",
              "4                           0.0                           13.0   \n",
              "\n",
              "   TERMINAL_ID_RISK_7DAY_WINDOW  TERMINAL_ID_NB_TX_30DAY_WINDOW  \\\n",
              "0                           0.0                            38.0   \n",
              "1                           0.0                            31.0   \n",
              "2                           0.0                            35.0   \n",
              "3                           0.0                            27.0   \n",
              "4                           0.0                            30.0   \n",
              "\n",
              "   TERMINAL_ID_RISK_30DAY_WINDOW  \n",
              "0                       0.000000  \n",
              "1                       0.032258  \n",
              "2                       0.000000  \n",
              "3                       0.000000  \n",
              "4                       0.000000  \n",
              "\n",
              "[5 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-40dfdc0d-896d-48a0-bbd0-297b4fcada27\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TRANSACTION_ID</th>\n",
              "      <th>TX_DATETIME</th>\n",
              "      <th>CUSTOMER_ID</th>\n",
              "      <th>TERMINAL_ID</th>\n",
              "      <th>TX_AMOUNT</th>\n",
              "      <th>TX_TIME_SECONDS</th>\n",
              "      <th>TX_TIME_DAYS</th>\n",
              "      <th>TX_FRAUD</th>\n",
              "      <th>TX_FRAUD_SCENARIO</th>\n",
              "      <th>TX_DURING_WEEKEND</th>\n",
              "      <th>...</th>\n",
              "      <th>CUSTOMER_ID_NB_TX_7DAY_WINDOW</th>\n",
              "      <th>CUSTOMER_ID_AVG_AMOUNT_7DAY_WINDOW</th>\n",
              "      <th>CUSTOMER_ID_NB_TX_30DAY_WINDOW</th>\n",
              "      <th>CUSTOMER_ID_AVG_AMOUNT_30DAY_WINDOW</th>\n",
              "      <th>TERMINAL_ID_NB_TX_1DAY_WINDOW</th>\n",
              "      <th>TERMINAL_ID_RISK_1DAY_WINDOW</th>\n",
              "      <th>TERMINAL_ID_NB_TX_7DAY_WINDOW</th>\n",
              "      <th>TERMINAL_ID_RISK_7DAY_WINDOW</th>\n",
              "      <th>TERMINAL_ID_NB_TX_30DAY_WINDOW</th>\n",
              "      <th>TERMINAL_ID_RISK_30DAY_WINDOW</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>680886</td>\n",
              "      <td>2018-06-11 00:00:24</td>\n",
              "      <td>3711</td>\n",
              "      <td>8121</td>\n",
              "      <td>75.81</td>\n",
              "      <td>6134424</td>\n",
              "      <td>71</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>34.0</td>\n",
              "      <td>69.421471</td>\n",
              "      <td>124.0</td>\n",
              "      <td>70.598710</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>680887</td>\n",
              "      <td>2018-06-11 00:00:25</td>\n",
              "      <td>1320</td>\n",
              "      <td>867</td>\n",
              "      <td>101.89</td>\n",
              "      <td>6134425</td>\n",
              "      <td>71</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>27.0</td>\n",
              "      <td>92.666667</td>\n",
              "      <td>117.0</td>\n",
              "      <td>83.699402</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0.032258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>680888</td>\n",
              "      <td>2018-06-11 00:01:46</td>\n",
              "      <td>824</td>\n",
              "      <td>7954</td>\n",
              "      <td>44.72</td>\n",
              "      <td>6134506</td>\n",
              "      <td>71</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>23.0</td>\n",
              "      <td>37.035217</td>\n",
              "      <td>80.0</td>\n",
              "      <td>40.290125</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>680889</td>\n",
              "      <td>2018-06-11 00:02:40</td>\n",
              "      <td>1085</td>\n",
              "      <td>8595</td>\n",
              "      <td>23.08</td>\n",
              "      <td>6134560</td>\n",
              "      <td>71</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>24.0</td>\n",
              "      <td>55.140833</td>\n",
              "      <td>101.0</td>\n",
              "      <td>54.151386</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>680890</td>\n",
              "      <td>2018-06-11 00:02:55</td>\n",
              "      <td>346</td>\n",
              "      <td>4909</td>\n",
              "      <td>98.13</td>\n",
              "      <td>6134575</td>\n",
              "      <td>71</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>7.0</td>\n",
              "      <td>57.628571</td>\n",
              "      <td>38.0</td>\n",
              "      <td>63.603158</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 23 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-40dfdc0d-896d-48a0-bbd0-297b4fcada27')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-40dfdc0d-896d-48a0-bbd0-297b4fcada27 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-40dfdc0d-896d-48a0-bbd0-297b4fcada27');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transactions_df.count(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3RDro4A5wbk",
        "outputId": "f3daa44f-bebc-4e95-dfcd-f59751f00547"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         23\n",
              "1         23\n",
              "2         23\n",
              "3         23\n",
              "4         23\n",
              "          ..\n",
              "919762    23\n",
              "919763    23\n",
              "919764    23\n",
              "919765    23\n",
              "919766    23\n",
              "Length: 919767, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting the starting day for the training period, and the deltas\n",
        "import datetime\n",
        "start_date_training = datetime.datetime.strptime(\"2018-07-25\", \"%Y-%m-%d\")\n",
        "delta_train=7\n",
        "delta_delay=7\n",
        "delta_test=7\n",
        "(train_df, test_df)=get_train_test_set(transactions_df,start_date_training,\n",
        "                                       delta_train=delta_train,delta_delay=delta_delay,delta_test=delta_test)\n",
        "# By default, scaling the input data\n",
        "(train_df, test_df)=scaleData(train_df,test_df,input_features)"
      ],
      "metadata": {
        "id": "utBkGD-hwKag"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = \"cuda\" \n",
        "else:\n",
        "    DEVICE = \"cpu\"\n",
        "print(\"Selected device is\",DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5dB31I4vpE1",
        "outputId": "b7767800-4ec3-4bb3-8fc1-d3d1db063f10"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected device is cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(SEED)"
      ],
      "metadata": {
        "id": "JGUOU-Tt1ssY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = torch.FloatTensor(train_df[input_features].values)\n",
        "x_test = torch.FloatTensor(test_df[input_features].values)\n",
        "y_train = torch.FloatTensor(train_df[output_feature].values)\n",
        "y_test = torch.FloatTensor(test_df[output_feature].values)"
      ],
      "metadata": {
        "id": "3Rlb_U0D2NTg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FraudDataset(torch.utils.data.Dataset):\n",
        "    \n",
        "    def __init__(self, x, y):\n",
        "        'Initialization'\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        'Returns the total number of samples'\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generates one sample of data'\n",
        "        # Select sample index\n",
        "        if self.y is not None:\n",
        "            return self.x[index].to(DEVICE), self.y[index].to(DEVICE)\n",
        "        else:\n",
        "            return self.x[index].to(DEVICE)"
      ],
      "metadata": {
        "id": "5esf_hLx2mWB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader_params = {'batch_size': 64,\n",
        "          'shuffle': True,\n",
        "          'num_workers': 0}\n",
        "test_loader_params = {'batch_size': 64,\n",
        "          'num_workers': 0}\n",
        "\n",
        "# Generators\n",
        "\n",
        "training_set = FraudDataset(x_train, y_train)\n",
        "\n",
        "testing_set = FraudDataset(x_test, y_test)\n",
        "\n",
        "\n",
        "training_generator = torch.utils.data.DataLoader(training_set, **train_loader_params)\n",
        "testing_generator = torch.utils.data.DataLoader(testing_set, **test_loader_params)"
      ],
      "metadata": {
        "id": "dKIEg2kQ2ril"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FraudDetectionFunction(torch.nn.Module):\n",
        "    \n",
        "        def __init__(self, input_size, hidden_size):\n",
        "            super(FraudDetectionFunction, self).__init__()\n",
        "            # parameters\n",
        "            self.input_size = input_size\n",
        "            self.hidden_size  = hidden_size\n",
        "            \n",
        "            #input to hidden\n",
        "            self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)\n",
        "            self.relu = torch.nn.ReLU()\n",
        "            #hidden to output\n",
        "            self.fc2 = torch.nn.Linear(self.hidden_size, 1)\n",
        "            self.sigmoid = torch.nn.Sigmoid()\n",
        "            \n",
        "        def forward(self, x):\n",
        "            \n",
        "            hidden = self.fc1(x)\n",
        "            relu = self.relu(hidden)\n",
        "            output = self.fc2(relu)\n",
        "            output = self.sigmoid(output)\n",
        "            \n",
        "            return output"
      ],
      "metadata": {
        "id": "cSyz2THm3AY6"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = FraudDetectionFunction(len(input_features), 1000).to(DEVICE)"
      ],
      "metadata": {
        "id": "Pro_rCzc3F7E"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Loss_cal = torch.nn.BCELoss().to(DEVICE)"
      ],
      "metadata": {
        "id": "GdsTZPg-3I_3"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b96me3NM3Lcx",
        "outputId": "81e4c264-a3f2-4550-ddb2-f7511c5b19a8"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleFraudMLP(\n",
              "  (fc1): Linear(in_features=15, out_features=1000, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (fc2): Linear(in_features=1000, out_features=1, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.07)"
      ],
      "metadata": {
        "id": "VWrNaYSu3Tpu"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model,generator,criterion):\n",
        "    model.eval()\n",
        "    batch_losses = []\n",
        "    for x_batch, y_batch in generator:\n",
        "        # Forward pass\n",
        "        y_pred = model(x_batch)\n",
        "        # Compute Loss\n",
        "        loss = Loss_cal(y_pred.squeeze(), y_batch)\n",
        "        batch_losses.append(loss.item())\n",
        "    mean_loss = np.mean(batch_losses)    \n",
        "    return mean_loss\n",
        "    \n"
      ],
      "metadata": {
        "id": "UrU6QqoN2ixg"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 100\n",
        "#Setting the model in training mode\n",
        "model.train()\n",
        "\n",
        "#Training loop\n",
        "start_time=time.time()\n",
        "epochs_train_losses = []\n",
        "epochs_test_losses = []\n",
        "for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    train_loss=[]\n",
        "    for x_batch, y_batch in training_generator:\n",
        "        # Removing previously computed gradients\n",
        "        optimizer.zero_grad()\n",
        "        # Performing the forward pass on the current batch\n",
        "        y_pred = model(x_batch)\n",
        "        # Computing the loss given the current predictions\n",
        "        loss = Loss_cal(y_pred.squeeze(), y_batch)\n",
        "        # Computing the gradients over the backward pass\n",
        "        loss.backward()\n",
        "        # Performing an optimization step from the current gradients\n",
        "        optimizer.step()\n",
        "        # Storing the current step's loss for display purposes\n",
        "        train_loss.append(loss.item())\n",
        "    \n",
        "    #showing last training loss after each epoch\n",
        "    epochs_train_losses.append(np.mean(train_loss))\n",
        "    print('Epoch {}: train loss: {}'.format(epoch, np.mean(train_loss)))\n",
        "    \n",
        "    #evaluating the model on the test set after each epoch    \n",
        "    val_loss = evaluate_model(model,testing_generator,Loss_cal)    \n",
        "    epochs_test_losses.append(val_loss)\n",
        "    print('test loss: {}'.format(val_loss))   \n",
        "    print(\"\")\n",
        "    \n",
        "training_execution_time=time.time()-start_time"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KR_Ff0GH3ZmF",
        "outputId": "cedd12d4-30bd-499a-b169-94547e14b96e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: train loss: 0.020105121838244353\n",
            "test loss: 0.020576184861102315\n",
            "\n",
            "Epoch 1: train loss: 0.0199879068139361\n",
            "test loss: 0.019304020325453905\n",
            "\n",
            "Epoch 2: train loss: 0.01980818898065262\n",
            "test loss: 0.019179853544755543\n",
            "\n",
            "Epoch 3: train loss: 0.019697639639697593\n",
            "test loss: 0.020206690379229307\n",
            "\n",
            "Epoch 4: train loss: 0.019521747176782657\n",
            "test loss: 0.020824221427780888\n",
            "\n",
            "Epoch 5: train loss: 0.019594767432417066\n",
            "test loss: 0.019731311617101187\n",
            "\n",
            "Epoch 6: train loss: 0.019669443302230465\n",
            "test loss: 0.020423690946650017\n",
            "\n",
            "Epoch 7: train loss: 0.019123128518177733\n",
            "test loss: 0.021321638913709633\n",
            "\n",
            "Epoch 8: train loss: 0.019162797378145732\n",
            "test loss: 0.020161859762321228\n",
            "\n",
            "Epoch 9: train loss: 0.019063850279257666\n",
            "test loss: 0.019954261164455422\n",
            "\n",
            "Epoch 10: train loss: 0.0189436037918831\n",
            "test loss: 0.01936014300054062\n",
            "\n",
            "Epoch 11: train loss: 0.018933517720925132\n",
            "test loss: 0.01910426763858049\n",
            "\n",
            "Epoch 12: train loss: 0.01901064051331139\n",
            "test loss: 0.020186042663197592\n",
            "\n",
            "Epoch 13: train loss: 0.01876636706208447\n",
            "test loss: 0.01985544140200702\n",
            "\n",
            "Epoch 14: train loss: 0.01865752582942498\n",
            "test loss: 0.0193914027492803\n",
            "\n",
            "Epoch 15: train loss: 0.018530619895113606\n",
            "test loss: 0.019694278437238387\n",
            "\n",
            "Epoch 16: train loss: 0.01843393797349082\n",
            "test loss: 0.02022771477990893\n",
            "\n",
            "Epoch 17: train loss: 0.018531419232232473\n",
            "test loss: 0.019074265341441587\n",
            "\n",
            "Epoch 18: train loss: 0.01831211653789709\n",
            "test loss: 0.018929613017963715\n",
            "\n",
            "Epoch 19: train loss: 0.018312453699597716\n",
            "test loss: 0.02097885975942351\n",
            "\n",
            "Epoch 20: train loss: 0.018254857803305005\n",
            "test loss: 0.01910651133376052\n",
            "\n",
            "Epoch 21: train loss: 0.01802826085243973\n",
            "test loss: 0.018799298156206685\n",
            "\n",
            "Epoch 22: train loss: 0.017947373246365573\n",
            "test loss: 0.018856214609740324\n",
            "\n",
            "Epoch 23: train loss: 0.01790058731132911\n",
            "test loss: 0.01898889848930479\n",
            "\n",
            "Epoch 24: train loss: 0.01789598134078252\n",
            "test loss: 0.019750530148486267\n",
            "\n",
            "Epoch 25: train loss: 0.01786968251878571\n",
            "test loss: 0.01899251525355994\n",
            "\n",
            "Epoch 26: train loss: 0.01784314003885572\n",
            "test loss: 0.019020260528168815\n",
            "\n",
            "Epoch 27: train loss: 0.017703733069788518\n",
            "test loss: 0.02479613093771991\n",
            "\n",
            "Epoch 28: train loss: 0.017690864341337053\n",
            "test loss: 0.019039327726695834\n",
            "\n",
            "Epoch 29: train loss: 0.017290807005570053\n",
            "test loss: 0.019229208044968464\n",
            "\n",
            "Epoch 30: train loss: 0.017363798113621338\n",
            "test loss: 0.01995058914835122\n",
            "\n",
            "Epoch 31: train loss: 0.017598465829378757\n",
            "test loss: 0.01965135986039836\n",
            "\n",
            "Epoch 32: train loss: 0.017308390669863172\n",
            "test loss: 0.01895989778863867\n",
            "\n",
            "Epoch 33: train loss: 0.017338317178821564\n",
            "test loss: 0.019677177913761446\n",
            "\n",
            "Epoch 34: train loss: 0.01706176785033083\n",
            "test loss: 0.018911582223547604\n",
            "\n",
            "Epoch 35: train loss: 0.017144308109968445\n",
            "test loss: 0.019045272181383063\n",
            "\n",
            "Epoch 36: train loss: 0.016946213732391142\n",
            "test loss: 0.01969124712506166\n",
            "\n",
            "Epoch 37: train loss: 0.017041536247877\n",
            "test loss: 0.018909035190292273\n",
            "\n",
            "Epoch 38: train loss: 0.01688793777644574\n",
            "test loss: 0.020082039817090173\n",
            "\n",
            "Epoch 39: train loss: 0.01690406838722605\n",
            "test loss: 0.0200805273447564\n",
            "\n",
            "Epoch 40: train loss: 0.0168126809916288\n",
            "test loss: 0.02136167640720226\n",
            "\n",
            "Epoch 41: train loss: 0.01678872093062965\n",
            "test loss: 0.0190239383012407\n",
            "\n",
            "Epoch 42: train loss: 0.016783292255440566\n",
            "test loss: 0.0187579368653377\n",
            "\n",
            "Epoch 43: train loss: 0.016586120046881675\n",
            "test loss: 0.018782518003670076\n",
            "\n",
            "Epoch 44: train loss: 0.016792442495859344\n",
            "test loss: 0.019504296909197326\n",
            "\n",
            "Epoch 45: train loss: 0.016501789352990383\n",
            "test loss: 0.01922336772477697\n",
            "\n",
            "Epoch 46: train loss: 0.01666959237947982\n",
            "test loss: 0.01902898612786667\n",
            "\n",
            "Epoch 47: train loss: 0.01645810286302676\n",
            "test loss: 0.01955810248879634\n",
            "\n",
            "Epoch 48: train loss: 0.016609985601734264\n",
            "test loss: 0.019246659428379616\n",
            "\n",
            "Epoch 49: train loss: 0.016313734938205354\n",
            "test loss: 0.019868114836791042\n",
            "\n",
            "Epoch 50: train loss: 0.016323585872698776\n",
            "test loss: 0.01988562067177578\n",
            "\n",
            "Epoch 51: train loss: 0.01639122863639754\n",
            "test loss: 0.018991311750429427\n",
            "\n",
            "Epoch 52: train loss: 0.016197526277832466\n",
            "test loss: 0.019354364676619537\n",
            "\n",
            "Epoch 53: train loss: 0.016011106041964537\n",
            "test loss: 0.018913859546270926\n",
            "\n",
            "Epoch 54: train loss: 0.016092340464125096\n",
            "test loss: 0.01870445533072613\n",
            "\n",
            "Epoch 55: train loss: 0.016173301707265577\n",
            "test loss: 0.019269972235997156\n",
            "\n",
            "Epoch 56: train loss: 0.016088934993964188\n",
            "test loss: 0.01885301680282386\n",
            "\n",
            "Epoch 57: train loss: 0.01591882815411302\n",
            "test loss: 0.01981499759856311\n",
            "\n",
            "Epoch 58: train loss: 0.01584792347535399\n",
            "test loss: 0.01951442089629013\n",
            "\n",
            "Epoch 59: train loss: 0.01596456474868703\n",
            "test loss: 0.019589393412242986\n",
            "\n",
            "Epoch 60: train loss: 0.0156877313931734\n",
            "test loss: 0.019278102569907196\n",
            "\n",
            "Epoch 61: train loss: 0.01576956327571281\n",
            "test loss: 0.01891585539083475\n",
            "\n",
            "Epoch 62: train loss: 0.015838442499670497\n",
            "test loss: 0.019037039924676723\n",
            "\n",
            "Epoch 63: train loss: 0.015662729235436434\n",
            "test loss: 0.01902674602999676\n",
            "\n",
            "Epoch 64: train loss: 0.015709564479173814\n",
            "test loss: 0.019711276146753984\n",
            "\n",
            "Epoch 65: train loss: 0.015567008476371174\n",
            "test loss: 0.01977977493994345\n",
            "\n",
            "Epoch 66: train loss: 0.015505831455590325\n",
            "test loss: 0.01889207627608683\n",
            "\n",
            "Epoch 67: train loss: 0.015453139794316962\n",
            "test loss: 0.019799900807650622\n",
            "\n",
            "Epoch 68: train loss: 0.015421999382811264\n",
            "test loss: 0.018812631012930132\n",
            "\n",
            "Epoch 69: train loss: 0.01552073907988371\n",
            "test loss: 0.019199620769889493\n",
            "\n",
            "Epoch 70: train loss: 0.01538365441665796\n",
            "test loss: 0.018846361714828775\n",
            "\n",
            "Epoch 71: train loss: 0.015522275678614078\n",
            "test loss: 0.020064276207210834\n",
            "\n",
            "Epoch 72: train loss: 0.015658764447418743\n",
            "test loss: 0.019351299904046874\n",
            "\n",
            "Epoch 73: train loss: 0.015216322139447836\n",
            "test loss: 0.018773367324574113\n",
            "\n",
            "Epoch 74: train loss: 0.01535152446954457\n",
            "test loss: 0.019129712694249415\n",
            "\n",
            "Epoch 75: train loss: 0.014974935283772754\n",
            "test loss: 0.01897966892247136\n",
            "\n",
            "Epoch 76: train loss: 0.01516490068298177\n",
            "test loss: 0.019192708404512378\n",
            "\n",
            "Epoch 77: train loss: 0.01507894282439036\n",
            "test loss: 0.01901901972434242\n",
            "\n",
            "Epoch 78: train loss: 0.01509017303360486\n",
            "test loss: 0.019980270611572065\n",
            "\n",
            "Epoch 79: train loss: 0.014986771090420497\n",
            "test loss: 0.019115782451631123\n",
            "\n",
            "Epoch 80: train loss: 0.014900582950415141\n",
            "test loss: 0.019433652874134465\n",
            "\n",
            "Epoch 81: train loss: 0.014552200135759846\n",
            "test loss: 0.01984817934541735\n",
            "\n",
            "Epoch 82: train loss: 0.01484308718880027\n",
            "test loss: 0.01923016833547047\n",
            "\n",
            "Epoch 83: train loss: 0.014916299252800084\n",
            "test loss: 0.01912498332707147\n",
            "\n",
            "Epoch 84: train loss: 0.014770797433550482\n",
            "test loss: 0.01943278620896184\n",
            "\n",
            "Epoch 85: train loss: 0.014751359059900262\n",
            "test loss: 0.02039330893541322\n",
            "\n",
            "Epoch 86: train loss: 0.01471417447310393\n",
            "test loss: 0.01885249610609732\n",
            "\n",
            "Epoch 87: train loss: 0.01460227439169826\n",
            "test loss: 0.01900132354845356\n",
            "\n",
            "Epoch 88: train loss: 0.014842297289242258\n",
            "test loss: 0.01887363148795678\n",
            "\n",
            "Epoch 89: train loss: 0.014568818638723283\n",
            "test loss: 0.019233633956825157\n",
            "\n",
            "Epoch 90: train loss: 0.014678904463323924\n",
            "test loss: 0.01920450135526727\n",
            "\n",
            "Epoch 91: train loss: 0.014365149261589409\n",
            "test loss: 0.019425255115285544\n",
            "\n",
            "Epoch 92: train loss: 0.014416997100635973\n",
            "test loss: 0.020875080975192868\n",
            "\n",
            "Epoch 93: train loss: 0.014303579223235904\n",
            "test loss: 0.01936850437436214\n",
            "\n",
            "Epoch 94: train loss: 0.014629318877092281\n",
            "test loss: 0.019349411506767812\n",
            "\n",
            "Epoch 95: train loss: 0.014394302586889732\n",
            "test loss: 0.020000537374628344\n",
            "\n",
            "Epoch 96: train loss: 0.014355103427410873\n",
            "test loss: 0.020482651086189452\n",
            "\n",
            "Epoch 97: train loss: 0.014363581807149679\n",
            "test loss: 0.01898778230846378\n",
            "\n",
            "Epoch 98: train loss: 0.014109857909742044\n",
            "test loss: 0.018728124252142247\n",
            "\n",
            "Epoch 99: train loss: 0.014395130472069431\n",
            "test loss: 0.019802605732604523\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(model,testing_generator,Loss_cal)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZI7xj7Js37xu",
        "outputId": "4ae94b77-e711-4653-9df9-3f8a46978ddb"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.019802605732604523"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ma_window = 10\n",
        "\n",
        "plt.plot(np.arange(len(epochs_train_losses)-ma_window + 1)+1, np.convolve(epochs_train_losses, np.ones(ma_window)/ma_window, mode='valid'))\n",
        "plt.plot(np.arange(len(epochs_test_losses)-ma_window + 1)+1, np.convolve(epochs_test_losses, np.ones(ma_window)/ma_window, mode='valid'))\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['train','valid'])\n",
        "#plt.ylim([0.01,0.06])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "mQHQqXdjwl0h",
        "outputId": "474c422a-8a5a-4c81-ffa2-1e4e52151daf"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fee21b3fac0>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def performance_assessment(predictions_df, output_feature='TX_FRAUD', \n",
        "                           prediction_feature='predictions', top_k_list=[100],\n",
        "                           rounded=True):\n",
        "    \n",
        "    AUC_ROC = metrics.roc_auc_score(predictions_df[output_feature], predictions_df[prediction_feature])\n",
        "    AP = metrics.average_precision_score(predictions_df[output_feature], predictions_df[prediction_feature])\n",
        "    \n",
        "    performances = pd.DataFrame([[AUC_ROC, AP]], \n",
        "                           columns=['AUC ROC','Average precision'])\n",
        "    \n",
        "    for top_k in top_k_list:\n",
        "    \n",
        "        _, _, mean_card_precision_top_k = card_precision_top_k(predictions_df, top_k)\n",
        "        performances['Card Precision@'+str(top_k)]=mean_card_precision_top_k\n",
        "        \n",
        "    if rounded:\n",
        "        performances = performances.round(3)\n",
        "    \n",
        "    return performances"
      ],
      "metadata": {
        "id": "RmFniLz4vZBh"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df=test_df\n",
        "predictions_df['predictions']=predictions_test.detach().cpu().numpy()\n",
        "    \n",
        "performance_assessment(predictions_df, top_k_list=[100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "5CPPviNm5UKO",
        "outputId": "e116d6ec-be6a-48f7-a8cd-df4615810ae3"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   AUC ROC  Average precision  Card Precision@100\n",
              "0    0.869              0.603               0.271"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a0a8cca1-17c0-4304-a6bf-779bf0e0acb0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AUC ROC</th>\n",
              "      <th>Average precision</th>\n",
              "      <th>Card Precision@100</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.869</td>\n",
              "      <td>0.603</td>\n",
              "      <td>0.271</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0a8cca1-17c0-4304-a6bf-779bf0e0acb0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a0a8cca1-17c0-4304-a6bf-779bf0e0acb0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a0a8cca1-17c0-4304-a6bf-779bf0e0acb0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    }
  ]
}