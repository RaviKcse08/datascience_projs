{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMm6UdQ7nO97rydA6Q3Xyml",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RaviKcse08/datascience_projs/blob/main/GloveVectorsWithCosineSimilarity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Downloaded GloVe vectors from https://nlp.stanford.edu/projects/glove/ with desired dimensionss\n",
        "glove_file_path = 'glove.6B.100d.txt'  # Replace with the path to your GloVe file\n",
        "word_vectors = {}\n",
        "with open(glove_file_path, 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.array(values[1:], dtype='float32')\n",
        "        word_vectors[word] = vector\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "83PkjyEvxIvA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "kqfhnSzIzjaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your 10 words\n",
        "words = [\"apple\", \"banana\", \"orange\", \"cherry\", \"berry\", \"papaya\", \"lemon\", \"grapes\", \"raspberry\", \"peach\"]\n",
        "\n",
        "# Get the GloVe vectors for the 10 words\n",
        "word_vectors_10 = [word_vectors[word] for word in words]\n",
        "\n",
        "# Compute cosine similarity matrix\n",
        "cosine_sim_matrix = cosine_similarity(word_vectors_10)\n",
        "\n",
        "# Print the cosine similarity matrix\n",
        "for row in cosine_sim_matrix:\n",
        "    print(row)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJGzUdeM0lxk",
        "outputId": "c63ebf4e-9e35-4519-8130-11dffa54b520"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.99999994 0.50544685 0.50070393 0.58431274 0.42840353 0.43106648\n",
            " 0.51760966 0.41807717 0.43495047 0.5589313 ]\n",
            "[0.50544685 0.99999994 0.4739553  0.5013424  0.41266185 0.62465894\n",
            " 0.5509266  0.41932556 0.501399   0.60730004]\n",
            "[0.50070393 0.4739553  1.0000002  0.6054634  0.43293762 0.383392\n",
            " 0.62519634 0.34583881 0.5145848  0.6168625 ]\n",
            "[0.58431274 0.5013424  0.6054634  1.         0.6590359  0.5060767\n",
            " 0.6304643  0.48565295 0.64773905 0.6888099 ]\n",
            "[0.42840353 0.41266185 0.43293762 0.6590359  1.         0.360549\n",
            " 0.5212548  0.25531536 0.47469664 0.63899803]\n",
            "[0.43106648 0.62465894 0.383392   0.5060767  0.360549   0.99999994\n",
            " 0.5668003  0.42704847 0.50642645 0.598052  ]\n",
            "[0.51760966 0.5509266  0.62519634 0.6304643  0.5212548  0.5668003\n",
            " 1.         0.39041457 0.6338281  0.67784846]\n",
            "[0.41807717 0.41932556 0.34583881 0.48565295 0.25531536 0.42704847\n",
            " 0.39041457 1.0000001  0.34834886 0.41913584]\n",
            "[0.43495047 0.501399   0.5145848  0.64773905 0.47469664 0.50642645\n",
            " 0.6338281  0.34834886 1.0000002  0.7130107 ]\n",
            "[0.5589313  0.60730004 0.6168625  0.6888099  0.63899803 0.598052\n",
            " 0.67784846 0.41913584 0.7130107  1.0000001 ]\n"
          ]
        }
      ]
    }
  ]
}